from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.operators.python import PythonOperator
import pandas as pd
import logging

# Default arguments cho DAG
default_args = {
    'owner': 'data_team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email': ['lehongtien19x@gmail.com'],  
    'email_on_failure': True,
    'email_on_retry': True,
    'email_on_success': True, 
    'retries': 3,
    'retry_delay': timedelta(minutes=1),
}

# Táº¡o DAG
dag = DAG(
    'ecommerce_etl_pipeline',
    default_args=default_args,
    description='ETL pipeline cho E-commerce data',
    schedule_interval=timedelta(minutes=1),  # Cháº¡y má»—i 1 phÃºt thay vÃ¬ 5 giÃ¢y
    catchup=False,
    tags=['etl', 'ecommerce', 'data_warehouse'],
)

def extract_and_transform_customers():
    """Extract customers tá»« source vÃ  transform"""
    logging.info("Báº¯t Ä‘áº§u extract customers data...")
    
    try:
        # Káº¿t ná»‘i tá»›i database
        postgres_hook = PostgresHook(postgres_conn_id='postgres_data')
        
        # Truncate table trÆ°á»›c
        postgres_hook.run("TRUNCATE TABLE target_data.dim_customers CASCADE;")
        
        # Extract query
        extract_query = """
        SELECT 
            customer_id,
            CONCAT(first_name, ' ', last_name) as full_name,
            email,
            city,
            country,
            created_at::date as created_date,
            CASE 
                WHEN (SELECT COUNT(*) FROM source_data.orders o WHERE o.customer_id = c.customer_id) >= 5 THEN 'VIP'
                WHEN (SELECT COUNT(*) FROM source_data.orders o WHERE o.customer_id = c.customer_id) >= 2 THEN 'Regular'
                ELSE 'New'
            END as customer_segment
        FROM source_data.customers c
        """
        
        df = postgres_hook.get_pandas_df(extract_query)
        logging.info(f"Extracted {len(df)} customers")
        
        if len(df) > 0:
            # Transform: ThÃªm is_active flag
            df['is_active'] = True
            
            # Insert data vá»›i auto-generated keys
            insert_query = """
            INSERT INTO target_data.dim_customers 
            (customer_id, full_name, email, city, country, created_date, customer_segment, is_active)
            VALUES %s
            """
            
            # Chuyá»ƒn Ä‘á»•i DataFrame thÃ nh list of tuples
            data_tuples = [tuple(row) for row in df.values]
            
            # Use psycopg2's execute_values for bulk insert
            from psycopg2.extras import execute_values
            conn = postgres_hook.get_conn()
            cur = conn.cursor()
            execute_values(cur, insert_query, data_tuples)
            conn.commit()
            cur.close()
            
            logging.info(f"Loaded {len(df)} customers vÃ o dim_customers")
        else:
            logging.warning("KhÃ´ng cÃ³ customer data Ä‘á»ƒ load")
            
    except Exception as e:
        logging.error(f"Lá»—i trong extract_and_transform_customers: {str(e)}")
        raise

def extract_and_transform_products():
    """Extract products tá»« source vÃ  transform"""
    logging.info("Báº¯t Ä‘áº§u extract products data...")
    
    try:
        postgres_hook = PostgresHook(postgres_conn_id='postgres_data')
        
        # Truncate table trÆ°á»›c
        postgres_hook.run("TRUNCATE TABLE target_data.dim_products CASCADE;")
        
        extract_query = """
        SELECT 
            product_id,
            product_name,
            category,
            price,
            CASE 
                WHEN price >= 500 THEN 'Premium'
                WHEN price >= 100 THEN 'Standard'
                ELSE 'Budget'
            END as price_tier,
            CASE 
                WHEN stock_quantity >= 100 THEN 'In Stock'
                WHEN stock_quantity >= 10 THEN 'Low Stock'
                ELSE 'Out of Stock'
            END as stock_status,
            supplier
        FROM source_data.products
        """
        
        df = postgres_hook.get_pandas_df(extract_query)
        logging.info(f"Extracted {len(df)} products")
        
        if len(df) > 0:
            # Insert data vá»›i auto-generated keys
            insert_query = """
            INSERT INTO target_data.dim_products 
            (product_id, product_name, category, price, price_tier, stock_status, supplier)
            VALUES %s
            """
            
            data_tuples = [tuple(row) for row in df.values]
            
            from psycopg2.extras import execute_values
            conn = postgres_hook.get_conn()
            cur = conn.cursor()
            execute_values(cur, insert_query, data_tuples)
            conn.commit()
            cur.close()
            
            logging.info(f"Loaded {len(df)} products vÃ o dim_products")
        else:
            logging.warning("KhÃ´ng cÃ³ product data Ä‘á»ƒ load")
            
    except Exception as e:
        logging.error(f"Lá»—i trong extract_and_transform_products: {str(e)}")
        raise

def extract_and_transform_sales():
    """Extract sales tá»« source vÃ  transform vÃ o fact table"""
    logging.info("Báº¯t Ä‘áº§u extract sales data...")
    
    try:
        postgres_hook = PostgresHook(postgres_conn_id='postgres_data')
        
        # Truncate table trÆ°á»›c
        postgres_hook.run("TRUNCATE TABLE target_data.fact_sales CASCADE;")
        
        # Join vá»›i dimension tables Ä‘á»ƒ láº¥y Ä‘Ãºng keys
        extract_query = """
        SELECT 
            o.order_id,
            dc.customer_key,
            dp.product_key,
            o.order_date::date as sale_date,
            oi.quantity,
            oi.unit_price,
            oi.total_price as total_amount,
            30.0 as profit_margin
        FROM source_data.orders o
        JOIN source_data.order_items oi ON o.order_id = oi.order_id
        JOIN target_data.dim_customers dc ON o.customer_id = dc.customer_id
        JOIN target_data.dim_products dp ON oi.product_id = dp.product_id
        WHERE o.status = 'completed'
        """
        
        df = postgres_hook.get_pandas_df(extract_query)
        logging.info(f"Extracted {len(df)} sales records")
        
        if len(df) > 0:
            # Insert data
            insert_query = """
            INSERT INTO target_data.fact_sales 
            (order_id, customer_key, product_key, sale_date, quantity, unit_price, total_amount, profit_margin)
            VALUES %s
            """
            
            data_tuples = [tuple(row) for row in df.values]
            
            from psycopg2.extras import execute_values
            conn = postgres_hook.get_conn()
            cur = conn.cursor()
            execute_values(cur, insert_query, data_tuples)
            conn.commit()
            cur.close()
            
            logging.info(f"Loaded {len(df)} sales records vÃ o fact_sales")
        else:
            logging.warning("KhÃ´ng cÃ³ sales data Ä‘á»ƒ load")
            
    except Exception as e:
        logging.error(f"Lá»—i trong extract_and_transform_sales: {str(e)}")
        raise

def create_daily_summary():
    """Táº¡o daily sales summary"""
    logging.info("Táº¡o daily sales summary...")
    
    try:
        postgres_hook = PostgresHook(postgres_conn_id='postgres_data')
        
        # Truncate table trÆ°á»›c
        postgres_hook.run("TRUNCATE TABLE target_data.daily_sales_summary;")
        
        summary_query = """
        INSERT INTO target_data.daily_sales_summary 
        (summary_date, total_orders, total_revenue, total_customers, avg_order_value, top_selling_category)
        SELECT 
            fs.sale_date,
            COUNT(DISTINCT fs.order_id) as total_orders,
            SUM(fs.total_amount) as total_revenue,
            COUNT(DISTINCT fs.customer_key) as total_customers,
            AVG(fs.total_amount) as avg_order_value,
            'Electronics' as top_selling_category  -- Simplified for now
        FROM target_data.fact_sales fs
        GROUP BY fs.sale_date
        """
        
        postgres_hook.run(summary_query)
        logging.info("Daily summary Ä‘Ã£ Ä‘Æ°á»£c táº¡o/cáº­p nháº­t")
        
    except Exception as e:
        logging.error(f"Lá»—i trong create_daily_summary: {str(e)}")
        raise

def check_order_milestone():
    """Kiá»ƒm tra sá»‘ lÆ°á»£ng orders vÃ  gá»­i notification khi Ä‘áº¡t 100 orders"""
    logging.info("Kiá»ƒm tra milestone orders...")
    
    try:
        postgres_hook = PostgresHook(postgres_conn_id='postgres_data')
        
        # Äáº¿m tá»•ng sá»‘ orders
        total_orders_query = "SELECT COUNT(*) FROM source_data.orders"
        total_orders = postgres_hook.get_first(total_orders_query)[0]
        
        # Äáº¿m orders hÃ´m nay
        today_orders_query = """
        SELECT COUNT(*) FROM source_data.orders 
        WHERE DATE(order_date) = CURRENT_DATE
        """
        today_orders = postgres_hook.get_first(today_orders_query)[0]
        
        logging.info(f"Tá»•ng sá»‘ orders: {total_orders}")
        logging.info(f"Orders hÃ´m nay: {today_orders}")
        
        # Kiá»ƒm tra milestone 100 orders
        if total_orders > 0 and total_orders % 100 == 0:
            logging.info(f"ðŸŽ‰ MILESTONE REACHED: {total_orders} orders!")
            
            # Táº¡o thÃ´ng bÃ¡o chi tiáº¿t
            milestone_info = f"""
            ðŸŽ‰ CHÃšC Má»ªNG! ÄÃƒ Äáº T MILESTONE {total_orders} ORDERS!
            
            ðŸ“Š Thá»‘ng kÃª:
            - Tá»•ng sá»‘ orders: {total_orders}
            - Orders hÃ´m nay: {today_orders}
            - Thá»i gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            
            Há»‡ thá»‘ng ETL Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t! ðŸš€
            """
            
            logging.info(milestone_info)
            
            # Raise exception Ä‘á»ƒ trigger email notification
            raise Exception(f"MILESTONE NOTIFICATION: ÄÃ£ Ä‘áº¡t {total_orders} orders! ðŸŽ‰")
        
        elif today_orders >= 10:  # Bonus: ThÃ´ng bÃ¡o khi cÃ³ nhiá»u orders trong ngÃ y
            logging.info(f"ðŸ“ˆ CÃ³ {today_orders} orders hÃ´m nay - hoáº¡t Ä‘á»™ng tÃ­ch cá»±c!")
            
    except Exception as e:
        if "MILESTONE NOTIFICATION" in str(e):
            # ÄÃ¢y lÃ  notification milestone, khÃ´ng pháº£i lá»—i tháº­t
            logging.info("ÄÃ£ gá»­i milestone notification")
            raise  # Raise láº¡i Ä‘á»ƒ trigger email
        else:
            logging.error(f"Lá»—i trong check_order_milestone: {str(e)}")
            raise

# Define tasks
extract_customers_task = PythonOperator(
    task_id='extract_transform_customers',
    python_callable=extract_and_transform_customers,
    dag=dag,
)

extract_products_task = PythonOperator(
    task_id='extract_transform_products',
    python_callable=extract_and_transform_products,
    dag=dag,
)

extract_sales_task = PythonOperator(
    task_id='extract_transform_sales',
    python_callable=extract_and_transform_sales,
    dag=dag,
)

create_summary_task = PythonOperator(
    task_id='create_daily_summary',
    python_callable=create_daily_summary,
    dag=dag,
)

check_milestone_task = PythonOperator(
    task_id='check_order_milestone',
    python_callable=check_order_milestone,
    dag=dag,
    # Cáº¥u hÃ¬nh email riÃªng cho milestone notifications
    email_on_failure=True,  # Sáº½ gá»­i email khi cÃ³ milestone
    email_on_retry=False,   # KhÃ´ng gá»­i email khi retry
)

# Data quality check task
data_quality_check = PostgresOperator(
    task_id='data_quality_check',
    postgres_conn_id='postgres_data',
    sql="""
    DO $$
    DECLARE
        customer_count INTEGER;
        product_count INTEGER;
        sales_count INTEGER;
    BEGIN
        SELECT COUNT(*) INTO customer_count FROM target_data.dim_customers;
        SELECT COUNT(*) INTO product_count FROM target_data.dim_products;
        SELECT COUNT(*) INTO sales_count FROM target_data.fact_sales;
        
        RAISE NOTICE 'Data quality check: % customers, % products, % sales', 
                     customer_count, product_count, sales_count;
                     
        IF customer_count = 0 THEN
            RAISE WARNING 'No customers in dim_customers';
        END IF;
        
        IF product_count = 0 THEN
            RAISE WARNING 'No products in dim_products';
        END IF;
        
        IF sales_count = 0 THEN
            RAISE WARNING 'No sales in fact_sales';
        END IF;
    END $$;
    """,
    dag=dag,
)

# Task dependencies - Customers vÃ  Products cháº¡y song song, sau Ä‘Ã³ Sales, rá»“i Summary, Quality Check vÃ  Milestone Check
[extract_customers_task, extract_products_task] >> extract_sales_task >> create_summary_task >> [data_quality_check, check_milestone_task] 